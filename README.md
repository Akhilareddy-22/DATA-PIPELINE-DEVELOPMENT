# DATA-PIPELINE-DEVELOPMENT

*COMPANY*: CODTECH IT SOLUTIONS

*NAME*:ALLIVADHA AKHILA REDDY

*INTERN ID*:CTIS1092

*DOMAIN*:DATA SCIENCE

*DURATION*:4 WEEKS

*MENTOR*: NEELA SANTOSH

# Data Pipeline Development - Internship Task 1

## Project Overview
This project focuses on building a simple and efficient Data Pipeline using Python to automate the process of data preprocessing, transformation, and loading (ETL). In real-world applications, raw data collected from different sources often contains missing values, duplicate records, and inconsistent formats. Such data cannot be directly used for analysis or machine learning models.
The main goal of this project is to clean raw CSV data and convert it into a structured and machine-learning-ready format. The pipeline uses popular Python libraries such as Pandas, NumPy, and Scikit-Learn to handle data efficiently and accurately. By automating the preprocessing steps, this project reduces manual effort and improves reliability.
This pipeline can be used by data analysts, data scientists, and machine learning engineers to prepare datasets before building predictive models. The final output is a clean dataset that can be directly used for visualization, statistical analysis, or machine learning training.
The project demonstrates how real-world data engineering workflows operate in industries such as banking, healthcare, e-commerce, and artificial intelligence systems. It also helps beginners understand the importance of data quality in decision-making systems.

The goal is to clean raw CSV data and prepare it for machine learning or analysis.

---

## Features
- Reads raw dataset from CSV file
- Handles categorical and numerical data
- Converts text columns into numeric values using Label Encoding
- Scales numerical columns using Standard Scaler
- Saves cleaned and transformed data into a new CSV file
- Fully automated ETL pipeline

---

## Technologies Used
- Python
- Pandas
- Scikit-learn
- VS Code

## How to Run the Project
1. Install required libraries:
```bash
pip install -r requirements.txt

2.Run the pipeline 
python data_pipeline.py

3.Output file will be generated as 
cleaned_data.csv

output
![Image](https://github.com/user-attachments/assets/8ec30fc6-188c-4427-9f61-388a4bce7277)

Output file will be generated as 
cleaned_data.csv
